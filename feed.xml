<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2025-01-17T08:42:33+00:00</updated><id>/feed.xml</id><title type="html">Lab IRoS, Fasilkom UI</title><subtitle>Lab IRoS ini berfokus pada penelitian yang berkaitan dengan pengembangan sistem robotik cerdas. Area kajiannya mencakup sistem sensor multimodal, model-model representasi data dan analitika untuk pengembilan keputusan pada sistem robotika, serta sistem aktuator robotika dinamis.</subtitle><entry><title type="html">Gradient Descent Simplified</title><link href="/2023/01/21/example-post-2.html" rel="alternate" type="text/html" title="Gradient Descent Simplified" /><published>2023-01-21T00:00:00+00:00</published><updated>2025-01-17T08:36:26+00:00</updated><id>/2023/01/21/example-post-2</id><content type="html" xml:base="/2023/01/21/example-post-2.html"><![CDATA[<!-- excerpt start -->
<p>Gradient descent is an optimization algorithm used to minimize a function. Gradient descent works by iteratively moving in the direction opposite to the gradient of the function, with the step size determined by a hyperparameter called “learning rate”. Gradient descent is commonly used in machine learning to adjust the parameters of a model in order to minimize the loss function, especially in deep learning. In deep learning, gradient descent will adjust every trainable weights and biases of the model in which when these weights and biases are used, the loss function will be minimum.</p>

<p>This article is originally published in <a href="https://www.cantorsparadise.com/gradient-descent-simplified-421b437507c0">Cantor’s Paradise</a> and is currently behind medium paywall. If you have medium subscription, please have a look at the original version.
<!-- excerpt end --></p>

<p>Mathematically speaking, gradient descent can be formulated as follow:
$$X_{t+1}=X_t - \alpha \nabla$$</p>

<p>where,</p>
<ol>
  <li>$X_{t+1}$ = new value of x after updated</li>
  <li>$X_t$ = current value of x</li>
  <li>$\alpha$ = learning rate</li>
  <li>$\nabla$ = gradient with respect to x</li>
</ol>

<p>There are several types of gradient descent, including:</p>
<ol>
  <li>batch gradient descent</li>
  <li>stochastic gradient descent (SGD)</li>
  <li>mini-batch gradient descent</li>
</ol>

<h1 id="batch-gradient-descent">Batch gradient descent</h1>
<p>Batch gradient descent is a type of gradient descent that update the parameters after forward and backward pass through the entire dataset. It is called “batch” gradient descent because it uses the entire dataset to compute the gradient of the loss function at each iteration. Batch gradient descent can be formulated as follows:
$$X_{t+1}=X_t - \alpha \sum_{1}^{n}\nabla$$</p>

<p>Where n is the number of samples in the entire dataset.</p>

<p>One of the main disadvantages of batch gradient descent is that it can be computationally expensive when the dataset is very large, as it requires a forward and backward pass through the entire dataset at each iteration.</p>

<p>In addition, if the dataset is noisy or has a lot of outliers, the loss function can oscillate and never converge to a minimum. In this case, a more sophisticated optimization algorithm such as stochastic gradient descent or mini-batch gradient descent may be more appropriate.</p>

<h1 id="stochastic-gradient-descent-sgd">Stochastic gradient descent (SGD)</h1>
<p>Unlike batch gradient descent, which uses the entire dataset to compute the gradient of the loss function at each iteration, SGD uses only one training sample at a time to update the parameters of the model.</p>

<p>SGD can be formulated as follows:
$$X_{t+1}=X_t - \alpha \nabla$$</p>

<p>One advantage of SGD over batch gradient descent is that it is computationally more efficient, as it requires only one forward and backward pass through the model for each training sample, rather than the entire dataset. Additionally, SGD can be implemented online, which means it can update the model parameters on-the-fly as new data arrives.</p>

<p>However, one disadvantage of SGD is that the cost function can oscillate and not converge to a minimum due to the high variance in the updates caused by the use of only one sample at a time. This can be mitigated by using a smaller learning rate and by using mini-batch gradient descent, which combines the benefits of both SGD and batch gradient descent.</p>

<h1 id="mini-batch-gradient-descent">Mini-batch gradient descent</h1>
<p>Mini-batch gradient descent is a compromise between batch gradient descent and stochastic gradient descent. Unlike batch gradient descent, which uses the entire dataset to compute the gradient of the loss function at each iteration, and SGD, which uses only one sample at a time, mini-batch gradient descent uses a small subset of the dataset, called a mini-batch, to compute the gradient at each iteration.</p>

<p>Mini-batch gradient descent can be formulated as follows:
$$X_{t+1}=X_t - \alpha \sum_{1}^{n}\nabla$$</p>

<p>Where n is the number of mini-batch or also known as batch size. In the case of mini-batch gradient descent, n must be &gt; 1 and &lt; the total number of samples in the entire dataset.</p>

<p>Mini-batch gradient descent can be seen as a trade-off between stochastic gradient descent and batch gradient descent. It has the advantage that it can reduce the noise of the updates, as the mini-batch is a good representation of the training data and it is less variance than stochastic gradient descent. Moreover, it’s more computationally efficient than batch gradient descent because it uses only a subset of the dataset. However, it is more computationally demanding than stochastic gradient descent, as it requires multiple forward and backward passes through the model for each mini-batch.</p>

<p>A commonly used mini-batch size is between 16 and 256. But the ideal mini-batch size depends on the specific problem and the computational resources available.</p>

<h1 id="example">Example</h1>
<p>Suppose a function of one variable is as follow: $f(x)=(x-1)^2$ with an initial x₀ of 2 and a learning rate of 0.3. We will do 5 iterations of stochastic gradient descent to minimize function $f(x)$.</p>

<p><img src="https://archive.ph/ia2xk/4a0df411d6f0b26a871865a88420758f786201ca.webp" alt="Alt text" /></p>

<p>Step 1: Find the derivative of $f(x)$ which is $f’(x) = 2(x-1)$
Step 2: Compute the gradient of $f’(x_0)$
$$f’(2) = 2(2-1)$$
$$f’(2) = 2$$
Step 3: Update x using the gradient descent formula
$$X_1 = 2 - (0.3 \times 2)$$
$$X_1 = 1.4$$</p>

<p><img src="https://archive.ph/ia2xk/3901fd17e66ca023b78c2820ffb913618ecf0350.webp" alt="Alt text" /></p>

<p>Step 4: Compute the gradient of $f’(x_1)$
$$f’(1.4) = 2(1.4-1)$$
$$f’(1.4) = 0.8$$
Step 5: Update x using the gradient descent formula
$$X_2 = 1.4 - (0.3 \times 0.8)$$
$$X_2 = 1.08$$</p>

<p><img src="https://archive.ph/ia2xk/e3611942c3f15830475bae58973fe3fa7add3edc.webp" alt="Alt text" /></p>

<p>Step 6: Compute the gradient of $f’(x_2)$
$$f’(1.08) = 2(1.08-1)$$
$$f’(1.08) = 0.16$$
Step 7: Update x using the gradient descent formula
$$X_3 = 1.08 - (0.3 \times 0.16)$$
$$X_3 = 1.032$$</p>

<p><img src="https://archive.ph/ia2xk/cf86aa2ded05a3e951ca6f8cbbf6d455ca45d0b4.webp" alt="Alt text" /></p>

<p>Step 8: Compute the gradient of $f’(x_3)$
$$f’(1.032) = 2(1.032-1)$$
$$f’(1.032) = 0.064$$
Step 9: Update x using the gradient descent formula
$$X_4 = 1.032 - (0.3 \times 0.064)$$
$$X_4 = 1.0128$$</p>

<p><img src="https://archive.ph/ia2xk/59b6f2c4f5ec25125cb90c645b1fbf9e63de4ba2.webp" alt="Alt text" /></p>

<p>Step 10: Compute the gradient of $f’(x_4)$
$$f’(1.0128) = 2(1.0128-1)$$
$$f’(1.0128) = 0.0256$$
Step 11: Update x using the gradient descent formula
$$X_5 = 1.0128 - (0.3 \times 0.0256)$$
$$X_5 = 1.00512$$</p>

<p><img src="https://archive.ph/ia2xk/73ea88d14e2359c135d548d67ed85c6c5e220ee7.webp" alt="Alt text" /></p>

<p>Since the gradient almost reached 0 which will give slight to no update for variable x anymore, it means that the function $f(x)$ is already at or near its minimum with $x=1.00512$. This point of gradient descent is also known as convergence. We can verify this by putting the resulting x into $f(x)$ which results in a number that is very close to 0.
$$f(1.00512) = (1.00512-1)^2$$
$$f(1.00512) = 0.0000262144$$</p>

<p>The number of iterations itself is a hyperparameter that one has to decide before performing gradient descent. Another way to know when to stop the iteration is by thresholding the gradient. As we iterate the gradient descent over and over again, the gradient tends to get smaller and smaller. When the gradient passes a certain threshold, that is when the iteration should be stopped. In the above example, we demonstrated 5 iterations. Of course, one can still continue the iteration until f(x) gets closer and closer to 0. The learning rate plays a crucial role in gradient descent, as the name suggests, it determines how big of a quantity should gradient descent update the variable x. If it is set too low, it will take a lot more iteration for gradient descent to converge, on the other hand, if it is set too high, it will create some oscillations or worse make the gradient descent divergence.</p>

<h1 id="overshooting-the-minimum">Overshooting the minimum</h1>
<p>Overshooting the minimum is a problem in gradient descent that usually occurs when the learning rate is set too high. The learning rate determines the step size that the algorithm takes in the direction of the negative gradient, and if it is set too high, the algorithm may take large steps and overshoot the minimum of the loss function. To avoid overshooting, one can simply decrease the learning rate.</p>

<p>Following is an example with a high learning rate which leads to oscillation:</p>

<p>Suppose a function of one variable as follow: $f(x)=(x-1)^2$ with an initial $x_0$ of 2 and a learning rate of 0.9. We will do 5 iterations of stochastic gradient descent to minimize function $f(x)$.</p>

<p><img src="https://archive.ph/ia2xk/b92965e8c9d1b4dfc02063bfda723d9978fc5fe8.webp" alt="Alt text" /></p>

<p>Step 1: Find the derivative of $f(x)$ which is $f’(x) = 2(x-1)$
Step 2: Compute the gradient of $f’(x_0)$
$$f’(2) = 2(2–1) = 2(1)$$
$$f’(2) = 2$$
Step 3: Update x using the gradient descent formula
$$x_1 = 2–(0.9 \times 2)$$
$$x_1 = 0.2$$</p>

<p><img src="https://archive.ph/ia2xk/f82922ae2c33ef47d7857e177787c4a7429ab11e.webp" alt="Alt text" /></p>

<p>Step 4: Compute the gradient of $f’(x_1)$
$$f’(0.2) = 2(0.2–1)$$
$$f’(0.2) = -1.6$$
Step 5: Update x using the gradient descent formula
$$x_2 = 0.2–(0.9 \times -1.6)$$
$$x_2 = 1.64$$</p>

<p><img src="https://archive.ph/ia2xk/3712617344571d40772a018b850d57fe34d572c4.webp" alt="Alt text" /></p>

<p>Step 6: Compute the gradient of $f’(x_2)$
$$f’(1.64) = 2(1.64–1)$$
$$f’(1.64) = 1.28$$
Step 7: Update x using the gradient descent formula
$$x_3 = 1.64–(0.9 \times 1.28)$$
$$x_3 = 0.488$$</p>

<p><img src="https://archive.ph/ia2xk/060b1de4e994b86c431c66c03c6b208705840c45.webp" alt="Alt text" /></p>

<p>Step 8: Compute the gradient of $f’(x_3)$
$$f’(0.488) = 2(0.488–1)$$
$$f’(0.488) = -1.024$$
Step 9: Update x using the gradient descent formula
$$x_4 = 0.488–(0.9 \times -1.024)$$
$$x_4 = 1.4096$$</p>

<p><img src="https://archive.ph/ia2xk/3e856e35bf7cad2b54a274abf9759af1101eab2a.webp" alt="Alt text" /></p>

<p>Step 10: Compute the gradient of $f’(x_4)$
$$f’(1.4096) = 2(1.4096–1)$$
$$f’(1.4096) = 0.8192$$
Step 11: Update x using the gradient descent formula
$$x_5 = 1.4096–(0.9 \times 0.8192)$$
$$x_5 = 0.67232$$</p>

<p><img src="https://archive.ph/ia2xk/30a8c231b24a56dd047389c8745a0d87a4036a24.webp" alt="Alt text" /></p>

<p>After 5 iterations, the function $f(x)$ is still not at its minimum. We can verify this by putting the resulting x into $f(x)$ which result is 0.1073741824. That is not quite close to 0.
$$f(0.67232) = (0.67232–1)^2$$
$$f(0.67232) = 0.1073741824$$</p>

<p>It might actually converge to 0 if we do more and more iterations. A high learning rate results in a very big update that leads to oscillations. Contrary to the previous example where we use a learning rate of 0.3, 5 iterations are enough for the gradient descent to converge.</p>

<p>Choosing the learning rate is a tricky part of gradient descent, like a two-edged sword. Too high will lead to oscillations or worse divergence. Too low will takes forever to converge.</p>

<h1 id="conclusion">Conclusion</h1>
<p>Gradient descent is an optimization algorithm used to minimize a function by updating parameters. In deep learning, it will find the weights and biases in which when those weights and biases are used, the loss function will be minimum. There are three types of gradient descent, batch gradient descent which takes the entire dataset to perform an update, Stochastic gradient descent (SGD) which takes only one sample to perform an update, and Mini-batch gradient descent which takes a subset of the dataset to perform an update. Gradient descent has a hyperparameter called learning rate which cannot be set too high or too low.</p>]]></content><author><name>Mgs M Luthfi Ramadhan</name></author><category term="Deep Learning" /><category term="Artificial Intelligence" /><category term="Machine Learning" /><category term="Mathematics" /><category term="Data Science" /><summary type="html"><![CDATA[Gradient descent is an optimization algorithm used to minimize a function. Gradient descent works by iteratively moving in the direction opposite to the gradient of the function, with the step size determined by a hyperparameter called “learning rate”. Gradient descent is commonly used in machine learning to adjust the parameters of a model in order to minimize the loss function, especially in deep learning. In deep learning, gradient descent will adjust every trainable weights and biases of the model in which when these weights and biases are used, the loss function will be minimum.]]></summary></entry><entry><title type="html">TF-IDF Simplified</title><link href="/2021/01/20/example-post-1.html" rel="alternate" type="text/html" title="TF-IDF Simplified" /><published>2021-01-20T00:00:00+00:00</published><updated>2025-01-17T08:36:26+00:00</updated><id>/2021/01/20/example-post-1</id><content type="html" xml:base="/2021/01/20/example-post-1.html"><![CDATA[<!-- excerpt start -->
<p>Most machine learning algorithms are fulfilled with mathematical things such as statistics, algebra, calculus and etc. They expect the data to be numerical such as a 2-dimensional array with rows as instances and columns as features. The problem with natural language is that the data is in the form of raw text, so that the text needs to be transformed into a vector. The process of transforming text into a vector is commonly referred to as text vectorization. It’s a fundamental process in natural language processing because none of the machine learning algorithms understand a text, not even computers. Text vectorization algorithm namely TF-IDF vectorizer, which is a very popular approach for traditional machine learning algorithms can help in transforming text into vectors.</p>

<p>This article is originally published in <a href="https://medium.com/towards-data-science/tf-idf-simplified-aba19d5f5530">Towards Data Science</a> and is currently behind medium paywall. If you have medium subscription, please have a look at the original version.
<!-- excerpt end --></p>

<h1 id="tf-idf">TF-IDF</h1>
<p>Term frequency-inverse document frequency is a text vectorizer that transforms the text into a usable vector. It combines 2 concepts, Term Frequency (TF) and Document Frequency (DF).</p>

<p>The term frequency is the number of occurrences of a specific term in a document. Term frequency indicates how important a specific term in a document. Term frequency represents every text from the data as a matrix whose rows are the number of documents and columns are the number of distinct terms throughout all documents.
Document frequency is the number of documents containing a specific term. Document frequency indicates how common the term is.</p>

<p>Inverse document frequency (IDF) is the weight of a term, it aims to reduce the weight of a term if the term’s occurrences are scattered throughout all the documents. IDF can be calculated as follow:
$${idf}_i=\log(\frac{n}{df_i})$$</p>

<p>Where idfᵢ is the IDF score for term i, ${df}_i$ is the number of documents containing term i, and n is the total number of documents. The higher the DF of a term, the lower the IDF for the term. When the number of DF is equal to n which means that the term appears in all documents, the IDF will be zero, since $log(1)$ is zero, when in doubt just put this term in the stopword list because it doesn’t provide much information.</p>

<p>The TF-IDF score as the name suggests is just a multiplication of the term frequency matrix with its IDF, it can be calculated as follow:
$$w_{i,j}={tf}_{i,j} \times {idf}_i$$</p>

<p>Where $w_{i,j}$ is TF-IDF score for term i in document j, ${tf}_{i,j}$ is term frequency for term i in document j, and ${df}_i$ is IDF score for term i.</p>

<h1 id="example">Example</h1>
<p>Suppose we have 3 texts and we need to vectorize these texts using TF-IDF.
<img src="https://archive.ph/8Sh0J/bb34f145575d833d1a39e674b9683335a864ab16.webp" alt="Alt text" /></p>

<h2 id="step-1">Step 1</h2>
<p>Create a term frequency matrix where rows are documents and columns are distinct terms throughout all documents. Count word occurrences in every text.
<img src="https://archive.ph/8Sh0J/82150f914b997894d130ba4b50cc5722525c173c.webp" alt="Alt text" /></p>

<h2 id="step-2">Step 2</h2>
<p>Compute inverse document frequency (IDF) using the previously explained formula.
<img src="https://archive.ph/8Sh0J/60d918258fb0c9a2fc310fec6a1cdffe89580092.webp" alt="Alt text" /></p>

<h2 id="step-3">Step 3</h2>
<p>Multiply TF matrix with IDF respectively
<img src="https://archive.ph/8Sh0J/99ef38c9b1da12ef5cfae59545fb8a08ae60b142.webp" alt="Alt text" /></p>

<p>That’s it 😃! the text is now ready to feed into a machine learning algorithm.</p>

<h1 id="limitations">Limitations</h1>
<ol>
  <li>It is only useful as a lexical level feature.</li>
  <li>Synonymities are neglected.</li>
  <li>It doesn’t capture semantic.</li>
  <li>The highest TF-IDF score may not make sense with the topic of the document, since IDF gives high weight if the DF of a term is low.</li>
  <li>It neglects the sequence of the terms.</li>
</ol>

<h1 id="conclusion">Conclusion</h1>
<p>In order to process natural language, the text must be represented as a numerical feature. The process of transforming text into a numerical feature is called text vectorization. TF-IDF is one of the most popular text vectorizers, the calculation is very simple and easy to understand. It gives the rare term high weight and gives the common term low weight.</p>]]></content><author><name>Mgs M Luthfi Ramadhan</name></author><category term="Data Science" /><category term="Artificial Intelligence" /><category term="Machine Learning" /><category term="NLP" /><category term="Data" /><summary type="html"><![CDATA[Most machine learning algorithms are fulfilled with mathematical things such as statistics, algebra, calculus and etc. They expect the data to be numerical such as a 2-dimensional array with rows as instances and columns as features. The problem with natural language is that the data is in the form of raw text, so that the text needs to be transformed into a vector. The process of transforming text into a vector is commonly referred to as text vectorization. It’s a fundamental process in natural language processing because none of the machine learning algorithms understand a text, not even computers. Text vectorization algorithm namely TF-IDF vectorizer, which is a very popular approach for traditional machine learning algorithms can help in transforming text into vectors.]]></summary></entry></feed>